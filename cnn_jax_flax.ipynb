{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEsj1nAbxKqL"
      },
      "outputs": [],
      "source": [
        "!pip install -q flax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "r_J-tlY-xhSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "l5KcYnDDxgzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets(num_epochs, batch_size):\n",
        "    train_ds = tfds.load(\"mnist\", split=\"train\")\n",
        "    test_ds = tfds.load(\"mnist\", split=\"test\")\n",
        "\n",
        "    train_ds = train_ds.map(\n",
        "        lambda sample: {\n",
        "            \"image\": tf.cast(sample[\"image\"], tf.float32) / 255.0,\n",
        "            \"label\": sample[\"label\"],\n",
        "        }\n",
        "    )\n",
        "    test_ds = test_ds.map(\n",
        "        lambda sample: {\n",
        "            \"image\": tf.cast(sample[\"image\"], tf.float32) / 255.0,\n",
        "            \"label\": sample[\"label\"],\n",
        "        }\n",
        "    )\n",
        "    train_ds = train_ds.repeat(num_epochs).shuffle(1024)\n",
        "    train_ds = train_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "    test_ds = test_ds.shuffle(1024)\n",
        "    test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "\n",
        "    return train_ds, test_ds\n"
      ],
      "metadata": {
        "id": "_zzINvEbxOmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create CNN"
      ],
      "metadata": {
        "id": "crUbWWDdxulj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "cbXIUyq-xrKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "        x = x.reshape((x.shape[0], -1))  # flatten\n",
        "        x = nn.Dense(features=256)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(features=10)(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8slofMMpx0yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View model layers"
      ],
      "metadata": {
        "id": "DtrN9pynx7hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "cnn = ConvNet()\n",
        "print(cnn.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 28, 28, 1))))"
      ],
      "metadata": {
        "id": "K-PQLCPyx3wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TrainState"
      ],
      "metadata": {
        "id": "iVwdHg6wyE8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q clu"
      ],
      "metadata": {
        "id": "t3Etar-sx_qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from clu import metrics\n",
        "from flax.training import train_state\n",
        "from flax import struct\n",
        "import optax"
      ],
      "metadata": {
        "id": "2_KcZU6IyJij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@struct.dataclass\n",
        "class Metrics(metrics.Collection):\n",
        "  accuracy: metrics.Accuracy\n",
        "  loss: metrics.Average.from_output('loss')"
      ],
      "metadata": {
        "id": "uCDBvf2ByOGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  metrics: Metrics\n",
        "\n",
        "def create_train_state(module, rng, learning_rate, momentum):\n",
        "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
        "  params = module.init(rng, jnp.ones([1, 28, 28, 1]))['params'] # initialize parameters by passing a template image\n",
        "  tx = optax.sgd(learning_rate, momentum)\n",
        "  return TrainState.create(\n",
        "      apply_fn=module.apply, params=params, tx=tx,\n",
        "      metrics=Metrics.empty())"
      ],
      "metadata": {
        "id": "MjGaWVHkySsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training step"
      ],
      "metadata": {
        "id": "dWhn5ZpMyV1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "  \"\"\"Train for a single step.\"\"\"\n",
        "  def loss_fn(params):\n",
        "    logits = state.apply_fn({'params': params}, batch['image'])\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "        logits=logits, labels=batch['label']).mean()\n",
        "    return loss\n",
        "  grad_fn = jax.grad(loss_fn)\n",
        "  grads = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state"
      ],
      "metadata": {
        "id": "Am3o7YFIyUfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric computation"
      ],
      "metadata": {
        "id": "WK6bHpfTyboa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_metrics(*, state, batch):\n",
        "  logits = state.apply_fn({'params': state.params}, batch['image'])\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "        logits=logits, labels=batch['label']).mean()\n",
        "  metric_updates = state.metrics.single_from_model_output(\n",
        "    logits=logits, labels=batch['label'], loss=loss)\n",
        "  metrics = state.metrics.merge(metric_updates)\n",
        "  state = state.replace(metrics=metrics)\n",
        "  return state"
      ],
      "metadata": {
        "id": "RSeZmSlsyZes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Evaluate"
      ],
      "metadata": {
        "id": "PweC-HjNygt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "train_ds, test_ds = get_datasets(num_epochs, batch_size)"
      ],
      "metadata": {
        "id": "Cr_9XVVYydPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(0)"
      ],
      "metadata": {
        "id": "1UMdG-sXykqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_rng = jax.random.PRNGKey(0)"
      ],
      "metadata": {
        "id": "NK9h3_z7ymY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "-g8Rkc9_yniw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = create_train_state(cnn, init_rng, learning_rate, momentum)\n",
        "del init_rng  # Must not be used anymore."
      ],
      "metadata": {
        "id": "fj_0YGnkyozq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps_per_epoch = train_ds.cardinality().numpy() // num_epochs"
      ],
      "metadata": {
        "id": "qTO_354Fyq7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_history = {'train_loss': [],\n",
        "                   'train_accuracy': [],\n",
        "                   'test_loss': [],\n",
        "                   'test_accuracy': []}"
      ],
      "metadata": {
        "id": "Jo-xcviBytlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step,batch in enumerate(train_ds.as_numpy_iterator()):\n",
        "\n",
        "  # Run optimization steps over training batches and compute batch metrics\n",
        "  state = train_step(state, batch) # get updated train state (which contains the updated parameters)\n",
        "  state = compute_metrics(state=state, batch=batch) # aggregate batch metrics\n",
        "\n",
        "  if (step+1) % num_steps_per_epoch == 0: # one training epoch has passed\n",
        "    for metric,value in state.metrics.compute().items(): # compute metrics\n",
        "      metrics_history[f'train_{metric}'].append(value) # record metrics\n",
        "    state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n",
        "\n",
        "    # Compute metrics on the test set after each training epoch\n",
        "    test_state = state\n",
        "    for test_batch in test_ds.as_numpy_iterator():\n",
        "      test_state = compute_metrics(state=test_state, batch=test_batch)\n",
        "\n",
        "    for metric,value in test_state.metrics.compute().items():\n",
        "      metrics_history[f'test_{metric}'].append(value)\n",
        "\n",
        "    print(f\"train epoch: {(step+1) // num_steps_per_epoch}, \"\n",
        "          f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
        "          f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n",
        "    print(f\"test epoch: {(step+1) // num_steps_per_epoch}, \"\n",
        "          f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
        "          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")"
      ],
      "metadata": {
        "id": "0cGh6ThnyvIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize metrics"
      ],
      "metadata": {
        "id": "qMXLU53gzJCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Visualization\n",
        "\n",
        "# Plot loss and accuracy in subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax1.set_title('Loss')\n",
        "ax2.set_title('Accuracy')\n",
        "for dataset in ('train','test'):\n",
        "  ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
        "  ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "0SAg7MdByxgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform inference on test set"
      ],
      "metadata": {
        "id": "4ZTz7hF3zmK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def pred_step(state, batch):\n",
        "  logits = state.apply_fn({'params': state.params}, batch['image'])\n",
        "  return logits.argmax(axis=1)"
      ],
      "metadata": {
        "id": "x5KdLj5YziHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = test_ds.as_numpy_iterator().next()\n",
        "pred = pred_step(state, test_batch)"
      ],
      "metadata": {
        "id": "AhtQzq65z6WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axis = plt.subplots(5, 5, figsize=(12, 12))\n",
        "for i, ax in enumerate(axis.flatten()):\n",
        "  ax.imshow(test_batch['image'][i, ..., 0], cmap='gray')\n",
        "  ax.set_title(f'label={pred[i]}')\n",
        "  ax.axis('off')"
      ],
      "metadata": {
        "id": "vA5NiHnI0EEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}